# å°ˆé¡ŒPython - å°ˆæ¡ˆçµæ§‹æ–‡ä»¶

**æ›´æ–°æ—¥æœŸï¼š** 2025å¹´11æœˆ15æ—¥  
**å°ˆæ¡ˆåç¨±ï¼š** æœå‹™æ¥­æ»¿æ„åº¦åˆ†æç³»çµ± - å¤šæ¨¡æ…‹æƒ…ç·’è¾¨è­˜  
**ç‹€æ…‹ï¼š** Phase 1 é‡æ§‹é€²è¡Œä¸­

---

## ğŸ“ å°ˆæ¡ˆçµæ§‹

```
å°ˆé¡Œpython/
â”œâ”€â”€ .env                          # ç’°å¢ƒè®Šæ•¸è¨­å®šæª”ï¼ˆgitignoreï¼‰
â”œâ”€â”€ .env.example                  # ç’°å¢ƒè®Šæ•¸ç¯„ä¾‹æª”
â”œâ”€â”€ .gitignore                    # Git å¿½ç•¥æª”æ¡ˆè¨­å®š
â”œâ”€â”€ README.md                     # å°ˆæ¡ˆèªªæ˜æ–‡ä»¶
â”œâ”€â”€ requirements.txt              # Python å¥—ä»¶ä¾è³´æ¸…å–®
â”‚
â”œâ”€â”€ config.py                     # è¨­å®šç®¡ç†æ¨¡çµ„ï¼ˆNEWï¼‰
â”œâ”€â”€ exceptions.py                 # è‡ªè¨‚ä¾‹å¤–é¡åˆ¥ï¼ˆNEWï¼‰
â”‚
â”œâ”€â”€ models/                       # è³‡æ–™æ¨¡å‹ç›®éŒ„ï¼ˆNEWï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ camera_state.py          # æ”å½±æ©Ÿç‹€æ…‹è³‡æ–™é¡åˆ¥
â”‚
â”œâ”€â”€ utils/                        # å·¥å…·å‡½å¼ç›®éŒ„ï¼ˆNEWï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logging_config.py        # æ—¥èªŒè¨­å®š
â”‚   â”œâ”€â”€ camera_processing.py     # æ”å½±æ©Ÿè™•ç†é‚è¼¯
â”‚   â”œâ”€â”€ classification.py        # å½±åƒåˆ†é¡é‚è¼¯
â”‚   â”œâ”€â”€ frame_capture.py         # ç•«é¢æ“·å–é‚è¼¯
â”‚   â”œâ”€â”€ display.py               # é¡¯ç¤ºè™•ç†é‚è¼¯
â”‚   â”œâ”€â”€ recording.py             # éŒ„å½±è™•ç†é‚è¼¯
â”‚   â””â”€â”€ exit_conditions.py       # é€€å‡ºæ¢ä»¶åˆ¤æ–·
â”‚
â”œâ”€â”€ tests/                        # æ¸¬è©¦ç›®éŒ„ï¼ˆNEWï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py              # pytest è¨­å®š
â”‚   â”œâ”€â”€ test_camera_state.py     # ç‹€æ…‹ç®¡ç†æ¸¬è©¦
â”‚   â”œâ”€â”€ test_config.py           # è¨­å®šè¼‰å…¥æ¸¬è©¦
â”‚   â”œâ”€â”€ test_camera_processing.py# è™•ç†é‚è¼¯æ¸¬è©¦
â”‚   â”œâ”€â”€ test_classification.py   # åˆ†é¡åŠŸèƒ½æ¸¬è©¦
â”‚   â””â”€â”€ test_emotion_scoring.py  # è©•åˆ†è¨ˆç®—æ¸¬è©¦
â”‚
â”œâ”€â”€ logs/                         # æ—¥èªŒæª”æ¡ˆç›®éŒ„ï¼ˆNEW, gitignoreï¼‰
â”‚   â””â”€â”€ emotion_analysis.log
â”‚
â”œâ”€â”€ project.py                    # ä¸»ç¨‹å¼ï¼ˆé‡æ§‹ä¸­ï¼‰
â”œâ”€â”€ Auto_Switch.py                # è‡ªå‹•åˆ‡æ›ç¨‹å¼ï¼ˆé‡æ§‹ä¸­ï¼‰
â”œâ”€â”€ report_main.py                # å ±å‘Šç”Ÿæˆä¸»ç¨‹å¼
â”‚
â”œâ”€â”€ docs/                         # æ–‡ä»¶ç›®éŒ„
â”‚   â”œâ”€â”€ SETUP.md                 # è©³ç´°è¨­å®šæŒ‡å—ï¼ˆNEWï¼‰
â”‚   â”œâ”€â”€ ARCHITECTURE.md          # æ¶æ§‹èªªæ˜ï¼ˆNEWï¼‰
â”‚   â”œâ”€â”€ API.md                   # API æ–‡ä»¶ï¼ˆNEWï¼‰
â”‚   â”œâ”€â”€ CONTRIBUTING.md          # è²¢ç»æŒ‡å—ï¼ˆNEWï¼‰
â”‚   â”œâ”€â”€ NAMING_CONVENTIONS.md    # å‘½åè¦ç¯„ï¼ˆNEWï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ architecture/            # æ¶æ§‹æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ backend-arch.md     # å¾Œç«¯æ¶æ§‹èªªæ˜
â”‚   â”‚   â””â”€â”€ frontend-arch.md    # å‰ç«¯æ¶æ§‹èªªæ˜
â”‚   â”‚
â”‚   â”œâ”€â”€ dev-prompt/              # é–‹ç™¼æç¤ºæ–‡ä»¶
â”‚   â”‚   â””â”€â”€ phase1.md           # Phase 1 é–‹ç™¼æŒ‡ç¤º
â”‚   â”‚
â”‚   â”œâ”€â”€ schedule/                # é€²åº¦ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ plans/              # è¨ˆç•«æ–‡ä»¶
â”‚   â”‚   â”‚   â””â”€â”€ phase1.md       # Phase 1 è©³ç´°è¨ˆç•«
â”‚   â”‚   â”œâ”€â”€ todo/               # å¾…è¾¦äº‹é …
â”‚   â”‚   â””â”€â”€ reports/            # å®Œæˆå ±å‘Š
â”‚   â”‚
â”‚   â””â”€â”€ specs/                   # è¦æ ¼æ–‡ä»¶
â”‚       â”œâ”€â”€ drafts/
â”‚       â”œâ”€â”€ features/
â”‚       â””â”€â”€ prompts/
â”‚
â”œâ”€â”€ haarcascade_*.xml            # OpenCV äººè‡‰è¾¨è­˜æ¨¡å‹æª”æ¡ˆ
â”‚
â”œâ”€â”€ report.HTML/CSS/JS           # å ±å‘Šå‰ç«¯æª”æ¡ˆ
â”œâ”€â”€ report2.HTML/CSS/JS          # å ±å‘Šå‰ç«¯æª”æ¡ˆï¼ˆç‰ˆæœ¬2ï¼‰
â”‚
â”œâ”€â”€ output_cam0.avi/mp4         # æ”å½±æ©Ÿ0è¼¸å‡ºå½±ç‰‡
â”œâ”€â”€ output_cam1.avi/mp4         # æ”å½±æ©Ÿ1è¼¸å‡ºå½±ç‰‡
â”‚
â”œâ”€â”€ .venv/                       # Python è™›æ“¬ç’°å¢ƒï¼ˆPython 3.8.8ï¼‰
â””â”€â”€ opencv-4.x/                  # OpenCV åŸå§‹ç¢¼ï¼ˆé–‹ç™¼ç”¨ï¼‰
```

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½æ¨¡çµ„

### 1. æƒ…ç·’è¾¨è­˜ç³»çµ± (`project.py`)

**ç•¶å‰ç‹€æ…‹ï¼š** é‡æ§‹ä¸­  
**åŠŸèƒ½ï¼š**
- é›™æ”å½±æ©Ÿå³æ™‚æƒ…ç·’åˆ†æ
- äººè‡‰åµæ¸¬èˆ‡è¿½è¹¤
- å¹´é½¡ã€æ€§åˆ¥ã€æƒ…ç·’è¾¨è­˜
- å½±ç‰‡éŒ„è£½èˆ‡å„²å­˜

**ä½¿ç”¨çš„æŠ€è¡“ï¼š**
- Keras æ¨¡å‹é€²è¡Œå ´æ™¯åˆ†é¡ï¼ˆäººå“¡é€²å…¥/é›¢é–‹ï¼‰
- DeepFace é€²è¡Œäººè‡‰åˆ†æ
- OpenCV é€²è¡Œå½±åƒè™•ç†å’Œæ”å½±æ©Ÿæ§åˆ¶
- PIL é€²è¡Œä¸­æ–‡æ–‡å­—æ¸²æŸ“

**é‡æ§‹è¨ˆç•«ï¼š**
- ğŸ”´ æ¶ˆé™¤ç¡¬ç·¨ç¢¼è·¯å¾‘ â†’ ä½¿ç”¨ç’°å¢ƒè®Šæ•¸
- ğŸ”´ é‡æ§‹è³‡æ–™çµæ§‹ â†’ ä½¿ç”¨ CameraState é¡åˆ¥
- ğŸ”´ æ¶ˆé™¤é‡è¤‡ç¨‹å¼ç¢¼ â†’ çµ±ä¸€è™•ç†é‚è¼¯
- ğŸ”´ åŠ å…¥éŒ¯èª¤è™•ç† â†’ é‡è©¦æ©Ÿåˆ¶èˆ‡æ¸…æ¥šéŒ¯èª¤è¨Šæ¯

---

## ğŸ“¦ ä¾è³´å¥—ä»¶

### æ ¸å¿ƒä¾è³´
```txt
keras
tensorflow
opencv-python
deepface
numpy
Pillow
matplotlib
python-dotenv  # NEW - ç’°å¢ƒè®Šæ•¸ç®¡ç†
```

### é–‹ç™¼ä¾è³´
```txt
pytest         # NEW - æ¸¬è©¦æ¡†æ¶
pytest-cov     # NEW - æ¸¬è©¦è¦†è“‹ç‡
mypy           # NEW - å‹åˆ¥æª¢æŸ¥
```

---

## ğŸ”§ è¨­å®šç®¡ç†

### ç’°å¢ƒè®Šæ•¸ï¼ˆ`.env`ï¼‰

```env
# æ¨¡å‹æª”æ¡ˆè·¯å¾‘
MODEL_DIR=./models
KERAS_MODEL_PATH=${MODEL_DIR}/keras_model.h5
LABELS_PATH=${MODEL_DIR}/labels.txt

# å­—é«”è·¯å¾‘
FONT_DIR=./fonts
FONT_PATH=${FONT_DIR}/NotoSansTC-VariableFont_wght.ttf

# è¼¸å‡ºè·¯å¾‘
OUTPUT_DIR=./output
LOG_DIR=./logs

# æ—¥èªŒè¨­å®š
LOG_LEVEL=INFO

# æ”å½±æ©Ÿè¨­å®š
CAMERA_0_ID=0
CAMERA_1_ID=1
```

---

## ğŸ“ é–‹ç™¼å·¥ä½œæµç¨‹

### 1. ç’°å¢ƒè¨­å®š
```bash
# å•Ÿå‹•è™›æ“¬ç’°å¢ƒ
```bash
source .venv/bin/activate
```

# å®‰è£ä¾è³´
pip install -r requirements.txt

# è¨­å®šç’°å¢ƒè®Šæ•¸
cp .env.example .env
# ç·¨è¼¯ .env æª”æ¡ˆï¼Œè¨­å®šæ­£ç¢ºçš„è·¯å¾‘
```

### 2. é–‹ç™¼
- éµå¾ªå‘½åè¦ç¯„
- ç‚ºæ–°åŠŸèƒ½æ’°å¯«æ¸¬è©¦
- ä½¿ç”¨å‹åˆ¥æç¤º
- æ’°å¯«æ¸…æ¥šçš„ docstring

### 3. æ¸¬è©¦
```bash
# åŸ·è¡Œæ¸¬è©¦
pytest

# å‹åˆ¥æª¢æŸ¥
mypy project.py utils/ models/
```

### 4. æäº¤
```bash
# éµå¾ª Conventional Commits
git commit -m "feat: add camera state management"
git commit -m "refactor: extract camera processing logic"
```

---

## ğŸ“Š é‡æ§‹é€²åº¦

### Phase 1: åŸºç¤é‡æ§‹ï¼ˆé€²è¡Œä¸­ï¼‰

- [ ] ä»»å‹™ 1: æ¶ˆé™¤ç¡¬ç·¨ç¢¼è·¯å¾‘
- [ ] ä»»å‹™ 2: é‡æ§‹è³‡æ–™çµæ§‹
- [ ] ä»»å‹™ 3: æ¶ˆé™¤é‡è¤‡ç¨‹å¼ç¢¼
- [ ] ä»»å‹™ 4: åŠ å…¥éŒ¯èª¤è™•ç†

---

**æœ€å¾Œæ›´æ–°ï¼š** 2025å¹´11æœˆ15æ—¥

## Running the System

### Prerequisites
```bash
pip install keras opencv-python numpy deepface pillow matplotlib flask ffmpeg-python
```

### Required External Files
- Keras model: `/Users/linjunting/Downloads/converted_keras-2/keras_model.h5`
- Labels file: `/Users/linjunting/Downloads/converted_keras-2/labels.txt`
- Font file: `/Users/linjunting/Downloads/Noto_Sans_TC/NotoSansTC-VariableFont_wght.ttf`
- Haar Cascade XMLs: `haarcascade_*.xml` (already in repo)

### Execution

**Manual mode:**
```bash
python project.py
```
- Press 'q' to manually stop analysis

**Auto-trigger mode:**
```bash
python Auto_Switch.py
```
- Automatically starts when face detected
- Press 'q' to exit monitoring

**View reports:**
```bash
python report_main.py
```
- Open browser to http://localhost:5000

## Key Implementation Details

### Camera Configuration
- Uses cameras at indices 0 and 1 (must have two USB/external cameras)
- Resolution: 320x240 (low-res for performance)
- Frame rate: 5 FPS target
- Analysis interval: Every 1 frame

### Performance Optimization
- Emotion analysis runs every frame_interval (default: 1 frame)
- Age/gender cached after 8 seconds to reduce DeepFace calls
- Previous results reused for skipped frames
- Low resolution preprocessing for classification model (224x224)

### Text Rendering
- Uses PIL ImageFont for Chinese character support (NotoSansTC)
- Custom `putText()` function overlays text on OpenCV frames

### Video Output
- Primary format: AVI (XVID codec)
- Automatic conversion to MP4 via ffmpeg after recording
- Separate files for each camera

## File Organization

**Core Scripts:**
- `project.py` - Main analysis (752 lines)
- `Auto_Switch.py` - Auto-trigger wrapper
- `report_main.py` - Flask web server

**Test/Development:**
- `test.py`, `test2.py` - Development/testing scripts
- `practice.py`, `Helloworld.py` - Learning examples
- `tempCodeRunnerFile.py` - VS Code runner temp file

**Assets:**
- `haarcascade_*.xml` - Face detection cascades
- `*.jpg`, `*.jpeg` - Test images and generated charts
- `output_cam*.mp4/avi` - Recorded sessions

**Web Interface:**
- `report2.HTML` - Main report template
- `report2.CSS` - Styling
- `report2.JS` - Client-side logic

## Branch Information

Current working branch: **AI_FRIEND**
(No main/master branch configured)

## Common Issues

1. **Camera not found**: Ensure two cameras connected at indices 0 and 1
2. **Model file missing**: Update hardcoded paths in scripts to your local model location
3. **Font rendering fails**: Verify NotoSansTC font path exists
4. **ffmpeg errors**: Ensure ffmpeg-python package installed (not system ffmpeg)
