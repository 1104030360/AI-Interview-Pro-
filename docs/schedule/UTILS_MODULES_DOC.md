# å·¥å…·æ¨¡çµ„å®Œæ•´æ–‡ä»¶

**å»ºç«‹æ—¥æœŸï¼š** 2025å¹´11æœˆ15æ—¥  
**ç‹€æ…‹ï¼š** âœ… å®Œæˆ

---

## ğŸ“¦ æ¨¡çµ„æ¶æ§‹

```
utils/
â”œâ”€â”€ __init__.py           # æ¨¡çµ„å°å‡º
â”œâ”€â”€ logging_config.py     # æ—¥èªŒç³»çµ±
â”œâ”€â”€ camera.py             # æ”å½±æ©Ÿç®¡ç†
â”œâ”€â”€ model.py              # æ¨¡å‹è¼‰å…¥
â”œâ”€â”€ classification.py     # å½±åƒåˆ†é¡
â”œâ”€â”€ analysis.py           # æƒ…ç·’åˆ†æ
â”œâ”€â”€ display.py            # é¡¯ç¤ºåŠŸèƒ½
â”œâ”€â”€ video.py              # è¦–è¨Šè™•ç†
â”œâ”€â”€ visualization.py      # åœ–è¡¨ç”Ÿæˆ
â””â”€â”€ camera_processing.py  # æ”å½±æ©Ÿè™•ç†é‚è¼¯
```

---

## ğŸ”§ æ¨¡çµ„è©³ç´°èªªæ˜

### 1. logging_config.py
**åŠŸèƒ½ï¼š** è¨­å®šå’Œç®¡ç†æ—¥èªŒç³»çµ±

**ä¸»è¦å‡½å¼ï¼š**
- `setup_logging()` - è¨­å®šæ—¥èªŒç³»çµ±ï¼ˆæª”æ¡ˆ + æ§åˆ¶å°ï¼‰
- `get_logger(name)` - ç²å–æŒ‡å®šåç¨±çš„ logger

**ç‰¹è‰²ï¼š**
- è‡ªå‹•æ—¥èªŒè¼ªæ›ï¼ˆ10MBï¼Œä¿ç•™5å€‹å‚™ä»½ï¼‰
- åŒæ™‚è¼¸å‡ºåˆ°æª”æ¡ˆå’Œæ§åˆ¶å°
- å¯è¨­å®šæ—¥èªŒç­‰ç´š

---

### 2. camera.py
**åŠŸèƒ½ï¼š** æ”å½±æ©Ÿåˆå§‹åŒ–ã€è¨­å®šå’Œè³‡æºç®¡ç†

**ä¸»è¦å‡½å¼ï¼š**
- `open_camera_with_retry(camera_id, max_retries=3)` - é–‹å•Ÿæ”å½±æ©Ÿï¼ˆå¸¶é‡è©¦ï¼‰
- `configure_camera(cap, fps, width, height)` - è¨­å®šæ”å½±æ©Ÿåƒæ•¸
- `read_frame(cap)` - è®€å–å½±åƒå¹€
- `release_camera(*caps)` - é‡‹æ”¾æ”å½±æ©Ÿè³‡æº
- `get_camera_info(cap)` - ç²å–æ”å½±æ©Ÿè³‡è¨Š

**ç‰¹è‰²ï¼š**
- è‡ªå‹•é‡è©¦æ©Ÿåˆ¶
- å®Œæ•´éŒ¯èª¤è™•ç†
- åƒæ•¸é©—è­‰

**ä½¿ç”¨ç¯„ä¾‹ï¼š**
```python
from utils import open_camera_with_retry, configure_camera

# é–‹å•Ÿä¸¦è¨­å®šæ”å½±æ©Ÿ
cap = open_camera_with_retry(0, max_retries=3)
configure_camera(cap, fps=5, width=320, height=240)
```

---

### 3. model.py
**åŠŸèƒ½ï¼š** Keras æ¨¡å‹è¼‰å…¥å’Œé©—è­‰

**ä¸»è¦å‡½å¼ï¼š**
- `load_keras_model(max_retries=3)` - è¼‰å…¥æ¨¡å‹å’Œæ¨™ç±¤
- `validate_model(model, expected_input_shape)` - é©—è­‰æ¨¡å‹

**ç‰¹è‰²ï¼š**
- è‡ªå‹•å¾ Config è®€å–è·¯å¾‘
- å¸¶é‡è©¦æ©Ÿåˆ¶
- æª”æ¡ˆå­˜åœ¨æ€§æª¢æŸ¥

**ä½¿ç”¨ç¯„ä¾‹ï¼š**
```python
from utils import load_keras_model

model, class_names = load_keras_model()
print(f"Loaded model with {len(class_names)} classes")
```

---

### 4. classification.py
**åŠŸèƒ½ï¼š** å½±åƒé è™•ç†å’Œåˆ†é¡

**ä¸»è¦å‡½å¼ï¼š**
- `preprocess_frame(frame, target_size=(224,224))` - é è™•ç†å½±åƒ
- `classify_frame(frame, model, class_names)` - åˆ†é¡å½±åƒ
- `is_person_detected(class_name, confidence_score)` - åˆ¤æ–·æ˜¯å¦åµæ¸¬åˆ°äºº
- `is_session_end(class_name)` - åˆ¤æ–·æ˜¯å¦çµæŸæœƒè©±

**ç‰¹è‰²ï¼š**
- æ¨™æº–åŒ–é è™•ç†æµç¨‹
- ä¿¡å¿ƒåº¦æª¢æŸ¥
- æ¸…æ™°çš„è¿”å›å€¼

**ä½¿ç”¨ç¯„ä¾‹ï¼š**
```python
from utils import classify_frame, is_person_detected

class_name, confidence = classify_frame(frame, model, class_names)
if is_person_detected(class_name, confidence):
    print("Person detected!")
```

---

### 5. analysis.py
**åŠŸèƒ½ï¼š** æƒ…ç·’ã€å¹´é½¡ã€æ€§åˆ¥åˆ†æ

**ä¸»è¦å‡½å¼ï¼š**
- `analyze_with_demographics(frame, class_name, confidence)` - å®Œæ•´åˆ†æ
- `analyze_emotions_only(frame, class_name, confidence)` - åƒ…æƒ…ç·’åˆ†æ
- `analyze_frame_with_retry(...)` - å¸¶é‡è©¦çš„åˆ†æ
- `categorize_emotion(emotion)` - æƒ…ç·’åˆ†é¡ï¼ˆæ­£/è² /ä¸­ï¼‰
- `map_emotion_to_score(emotion)` - æƒ…ç·’æ˜ å°„ç‚ºåˆ†æ•¸
- `calculate_emotion_statistics(emotions)` - è¨ˆç®—æƒ…ç·’çµ±è¨ˆ
- `calculate_satisfaction_score(emotions, baseline=60)` - è¨ˆç®—æ»¿æ„åº¦åˆ†æ•¸

**ç‰¹è‰²ï¼š**
- å®Œæ•´çš„ DeepFace æ•´åˆ
- é‡è©¦æ©Ÿåˆ¶
- è©³ç´°çš„çµ±è¨ˆè¨ˆç®—
- æ»¿æ„åº¦åˆ†æ•¸æ¼”ç®—æ³•

**ä½¿ç”¨ç¯„ä¾‹ï¼š**
```python
from utils import analyze_with_demographics, calculate_satisfaction_score

# åˆ†æå–®ä¸€ç•«é¢
result = analyze_with_demographics(frame, 'Class 1', 0.95)
print(f"Emotion: {result['emotion']}, Age: {result['age']}")

# è¨ˆç®—æ»¿æ„åº¦
emotions = ['happy', 'neutral', 'sad', 'happy']
score = calculate_satisfaction_score(emotions)
print(f"Satisfaction: {score}/100")
```

---

### 6. display.py
**åŠŸèƒ½ï¼š** å½±åƒé¡¯ç¤ºå’Œæ–‡å­—ç¹ªè£½

**ä¸»è¦å‡½å¼ï¼š**
- `put_text_chinese(img, text, x, y, font_size, color)` - ç¹ªè£½ä¸­æ–‡æ–‡å­—
- `draw_analysis_results(img, results, show_demographics)` - ç¹ªè£½åˆ†æçµæœ
- `resize_and_flip_frame(frame, target_size, flip)` - èª¿æ•´å’Œç¿»è½‰
- `create_split_screen(frame1, frame2, orientation)` - å»ºç«‹åˆ†å‰²ç•«é¢

**ç‰¹è‰²ï¼š**
- ä¸­æ–‡å­—é«”æ”¯æ´
- çµ±ä¸€çš„é¡¯ç¤ºæ ¼å¼
- å½ˆæ€§çš„ä½ˆå±€é¸é …

**ä½¿ç”¨ç¯„ä¾‹ï¼š**
```python
from utils import draw_analysis_results, put_text_chinese

# ç¹ªè£½å®Œæ•´åˆ†æçµæœ
img = draw_analysis_results(img, result, show_demographics=True)

# ç¹ªè£½è‡ªè¨‚æ–‡å­—
img = put_text_chinese(img, "åµæ¸¬ä¸­...", 10, 30, font_size=32)
```

---

### 7. video.py
**åŠŸèƒ½ï¼š** è¦–è¨ŠéŒ„è£½å’Œæ ¼å¼è½‰æ›

**ä¸»è¦å‡½å¼ï¼š**
- `create_video_writer(output_path, fps, frame_size, fourcc)` - å»ºç«‹éŒ„å½±å™¨
- `convert_avi_to_mp4(input_file, output_file, remove_source)` - æ ¼å¼è½‰æ›
- `release_video_resources(*writers)` - é‡‹æ”¾è³‡æº
- `get_video_info(video_path)` - ç²å–è¦–è¨Šè³‡è¨Š

**ç‰¹è‰²ï¼š**
- FFmpeg æ•´åˆ
- è‡ªå‹•æ ¼å¼è½‰æ›
- å®Œæ•´çš„éŒ¯èª¤è™•ç†

**ä½¿ç”¨ç¯„ä¾‹ï¼š**
```python
from utils import create_video_writer, convert_avi_to_mp4

# å»ºç«‹éŒ„å½±å™¨
writer = create_video_writer('output.avi', fps=5, frame_size=(320, 240))

# éŒ„è£½å¾Œè½‰æ›
convert_avi_to_mp4('output.avi', 'output.mp4', remove_source=True)
```

---

### 8. visualization.py
**åŠŸèƒ½ï¼š** ç”Ÿæˆæƒ…ç·’åˆ†æåœ–è¡¨

**ä¸»è¦å‡½å¼ï¼š**
- `generate_emotion_wave_chart(emotions, output_path, ...)` - æ³¢å‹•åœ–
- `generate_emotion_bar_chart(emotions, output_path, ...)` - é•·æ¢åœ–
- `generate_combined_wave_chart(emotions1, emotions2, ...)` - é›™æ”å½±æ©Ÿå°æ¯”åœ–
- `generate_demographics_title(ages, genders)` - ç”Ÿæˆæ¨™é¡Œ
- `generate_all_charts(emotions, ages, genders, ...)` - ç”Ÿæˆæ‰€æœ‰åœ–è¡¨

**ç‰¹è‰²ï¼š**
- Matplotlib æ•´åˆ
- ç¾è§€çš„åœ–è¡¨è¨­è¨ˆ
- è‡ªå‹•è¨ˆç®—çµ±è¨ˆ
- æ”¯æ´é›™æ”å½±æ©Ÿå°æ¯”

**ä½¿ç”¨ç¯„ä¾‹ï¼š**
```python
from utils import generate_all_charts

# ç”Ÿæˆæ‰€æœ‰åœ–è¡¨
emotions = ['happy', 'neutral', 'sad']
ages = [25, 26, 25]
genders = [('Male', 0.92), ('Male', 0.91), ('Male', 0.93)]

generate_all_charts(emotions, ages, genders, camera_name='Customer')
```

---

### 9. camera_processing.py
**åŠŸèƒ½ï¼š** çµ±ä¸€çš„æ”å½±æ©Ÿè™•ç†é‚è¼¯

**ä¸»è¦å‡½å¼ï¼š**
- `process_camera_frame(...)` - è™•ç†å–®ä¸€æ”å½±æ©Ÿå¹€
- `should_exit(camera_states, frame_count)` - åˆ¤æ–·æ˜¯å¦é€€å‡º

**ç‰¹è‰²ï¼š**
- æ¶ˆé™¤é›™æ”å½±æ©Ÿé‡è¤‡ç¨‹å¼ç¢¼
- çµ±ä¸€çš„é‚è¼¯æµç¨‹
- CameraState æ•´åˆ

**ä½¿ç”¨ç¯„ä¾‹ï¼š**
```python
from utils import process_camera_frame
from models import CameraState

state = CameraState()
result = process_camera_frame(
    frame, model, class_names, state, 
    camera_name='customer'
)
```

---

## ğŸ“Š ç¨‹å¼ç¢¼çµ±è¨ˆ

| æ¨¡çµ„ | è¡Œæ•¸ | å‡½å¼æ•¸ | ç”¨é€” |
|-----|------|--------|------|
| logging_config.py | 60 | 2 | æ—¥èªŒç³»çµ± |
| camera.py | 170 | 6 | æ”å½±æ©Ÿç®¡ç† |
| model.py | 90 | 2 | æ¨¡å‹è¼‰å…¥ |
| classification.py | 120 | 4 | å½±åƒåˆ†é¡ |
| analysis.py | 280 | 8 | æƒ…ç·’åˆ†æ |
| display.py | 140 | 4 | é¡¯ç¤ºåŠŸèƒ½ |
| video.py | 140 | 4 | è¦–è¨Šè™•ç† |
| visualization.py | 250 | 5 | åœ–è¡¨ç”Ÿæˆ |
| camera_processing.py | 160 | 2 | è™•ç†é‚è¼¯ |
| **ç¸½è¨ˆ** | **~1,410** | **37** | **å®Œæ•´å·¥å…·é›†** |

---

## ğŸ¯ ä½¿ç”¨æ–¹å¼

### ç°¡åŒ–å°å…¥

æ‰€æœ‰å‡½å¼éƒ½å¯ä»¥å¾ `utils` ç›´æ¥å°å…¥ï¼š

```python
from utils import (
    setup_logging,
    load_keras_model,
    open_camera_with_retry,
    classify_frame,
    analyze_with_demographics,
    draw_analysis_results,
    generate_all_charts
)
```

### å®Œæ•´ç¯„ä¾‹

```python
from config import Config
from models import CameraState
from utils import (
    setup_logging, get_logger,
    load_keras_model,
    open_camera_with_retry,
    configure_camera,
    classify_frame,
    analyze_with_demographics,
    draw_analysis_results,
    generate_all_charts
)

# 1. åˆå§‹åŒ–
config = Config()
setup_logging()
logger = get_logger(__name__)

# 2. è¼‰å…¥æ¨¡å‹
model, class_names = load_keras_model()

# 3. é–‹å•Ÿæ”å½±æ©Ÿ
cap = open_camera_with_retry(0)
configure_camera(cap)

# 4. åˆå§‹åŒ–ç‹€æ…‹
state = CameraState()

# 5. è™•ç†ç•«é¢
ret, frame = cap.read()
class_name, confidence = classify_frame(frame, model, class_names)
result = analyze_with_demographics(frame, class_name, confidence)

# 6. é¡¯ç¤ºçµæœ
img = draw_analysis_results(frame, result)

# 7. ç”Ÿæˆåœ–è¡¨
generate_all_charts(
    state.emotions,
    state.ages,
    state.genders,
    camera_name='Camera0'
)
```

---

## âœ… é©—è­‰æ¸…å–®

- [x] æ‰€æœ‰æ¨¡çµ„å·²å»ºç«‹
- [x] æ‰€æœ‰å‡½å¼éƒ½æœ‰ docstring
- [x] æ‰€æœ‰å‡½å¼éƒ½æœ‰å‹åˆ¥æç¤º
- [x] æ‰€æœ‰æ¨¡çµ„éƒ½æœ‰éŒ¯èª¤è™•ç†
- [x] æ‰€æœ‰æ¨¡çµ„éƒ½æœ‰æ—¥èªŒæ•´åˆ
- [x] __init__.py å·²æ›´æ–°
- [x] Git å·²æäº¤

---

## ğŸ”„ èˆ‡åŸå§‹ç¨‹å¼ç¢¼çš„å°æ‡‰

| åŸå§‹åŠŸèƒ½ | å°æ‡‰æ¨¡çµ„ | å°æ‡‰å‡½å¼ |
|---------|---------|---------|
| `load_model()` | model.py | `load_keras_model()` |
| `process_frame()` | classification.py | `classify_frame()` |
| `putText()` | display.py | `put_text_chinese()` |
| `analyze_frame_A()` | analysis.py | `analyze_with_demographics()` |
| `analyze_frame_B()` | analysis.py | `analyze_emotions_only()` |
| `convert_avi_to_mp4()` | video.py | `convert_avi_to_mp4()` |
| æƒ…ç·’æ³¢å‹•åœ– | visualization.py | `generate_emotion_wave_chart()` |
| æƒ…ç·’é•·æ¢åœ– | visualization.py | `generate_emotion_bar_chart()` |
| æ”å½±æ©Ÿåˆå§‹åŒ– | camera.py | `open_camera_with_retry()` + `configure_camera()` |
| æ»¿æ„åº¦è¨ˆç®— | analysis.py | `calculate_satisfaction_score()` |

---

## ğŸ“ ä¸‹ä¸€æ­¥

ç¾åœ¨æ‰€æœ‰å·¥å…·æ¨¡çµ„éƒ½å·²å®Œæˆï¼Œå¯ä»¥é–‹å§‹ï¼š

1. **é‡å¯« project.py** - ä½¿ç”¨æ–°æ¨¡çµ„
2. **æ’°å¯«æ¸¬è©¦** - ç‚ºæ–°æ¨¡çµ„å»ºç«‹æ¸¬è©¦
3. **æ•´åˆæ¸¬è©¦** - ç¢ºä¿åŠŸèƒ½ä¸€è‡´

---

**æœ€å¾Œæ›´æ–°ï¼š** 2025å¹´11æœˆ15æ—¥  
**ç‹€æ…‹ï¼š** æ‰€æœ‰å·¥å…·æ¨¡çµ„å®Œæˆ âœ…
